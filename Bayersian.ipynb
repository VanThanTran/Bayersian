{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import sklearn, os, time, h5py\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from math import floor\n",
    "from tensorflow.keras.applications import InceptionV3, DenseNet121\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'C:/Users/USER/Downloads/anhi/'\n",
    "import zipfile\n",
    "with zipfile.ZipFile(root_path + \"Dataset.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(root_path + \"\")\n",
    "\n",
    "datasetFolderName = root_path + 'Dataset'\n",
    "sourceFiles = []\n",
    "classLabels = ['light', 'moderate', 'no', 'severe']\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "img_rows, img_cols = 224, 224 \n",
    "train_path = datasetFolderName+'/train/'\n",
    "validation_path = datasetFolderName+'/valid/'\n",
    "test_path = datasetFolderName+'/test/'\n",
    "\n",
    "def transferBetweenFolders(source, dest, splitRate): \n",
    "    global sourceFiles\n",
    "    sourceFiles = os.listdir(source)\n",
    "    if(len(sourceFiles)!=0):\n",
    "        transferFileNumbers = int(len(sourceFiles)*splitRate)\n",
    "        transferIndex = random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")\n",
    "        \n",
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n",
    "                               datasetFolderName+'/'+dest+'/'+label+'/', splitRate)\n",
    "                               \n",
    "def my_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1Score = f1_score(y_true, y_pred, average='weighted') \n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"recall : {}\".format(recall))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    return accuracy, precision, recall, f1Score\n",
    "\n",
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName)\n",
    "    for val in sourceFiles:\n",
    "        X.append(val)\n",
    "        for i in range(len(classLabels)):\n",
    "            if(folderName==classLabels[i]):\n",
    "                Y.append(i)\n",
    "for i in range(len(classLabels)):\n",
    "    prepareNameWithLabels(classLabels[i])\n",
    "    \n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def nn_cl_bo(neurons1, neurons2, activation, optimizer, learning_rate, epochs, batch_size, dropout_rate, \n",
    "             layers1, layers2, dropout):\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop']\n",
    "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate), 'RMSprop':RMSprop(lr=learning_rate)}               \n",
    "    activationL = ['relu', 'sigmoid', 'selu', 'tanh', 'elu']\n",
    "\n",
    "    neurons1 = round(neurons1)  \n",
    "    neurons2 = round(neurons2)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = (optimizerD[optimizerL[round(optimizer)]])\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def CNN_model():\n",
    "        mobilenet = MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "        for layer in mobilenet.layers:\n",
    "            layer.trainable = False\n",
    "        x = Flatten()(mobilenet.output)\n",
    "        \n",
    "        for i in range(layers1):\n",
    "            x = Dense(neurons1, activation = activation)(x)\n",
    "        if dropout > 0.5:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "        for i in range(layers2):\n",
    "            x = Dense(neurons2, activation = activation)(x)\n",
    "\n",
    "        prediction = Dense(len(classLabels), activation='softmax')(x)\n",
    "        model = Model(inputs=mobilenet.input, outputs=prediction)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])       \n",
    "        return model\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    skf.get_n_splits(X, Y)\n",
    "    foldNum = 0\n",
    "    for train_index, val_index in skf.split(X, Y):\n",
    "        transferAllClassBetweenFolders('valid', 'train', 1.0)\n",
    "        foldNum += 1\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "        for eachIndex in range(len(X_val)):\n",
    "            classLabel = ''\n",
    "            for i in range(len(classLabels)):\n",
    "                if(Y_val[eachIndex]==i):\n",
    "                    classLabel=classLabels[i]\n",
    "            shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
    "                        datasetFolderName+'/valid/'+classLabel+'/'+X_val[eachIndex])   \n",
    "            \n",
    "        train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "        validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            train_path,target_size=(img_rows, img_cols),\n",
    "            batch_size=batch_size, class_mode='categorical', subset='training')     \n",
    "\n",
    "        validation_generator = validation_datagen.flow_from_directory(\n",
    "            validation_path,  target_size=(img_rows, img_cols),\n",
    "            batch_size=batch_size, class_mode='categorical')   \n",
    "\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            test_path, target_size=(img_rows, img_cols),\n",
    "            batch_size=batch_size,  class_mode=None, shuffle=False) \n",
    "    \n",
    "    \n",
    "    model1=CNN_model()\n",
    "    history=model1.fit_generator(train_generator, validation_data=validation_generator, epochs=epochs)\n",
    "\n",
    "    predictions = model1.predict(test_generator, verbose=1)\n",
    "    yPredictions = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    \n",
    "    score = accuracy_score(true_classes, yPredictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... | neurons1  | neurons2  | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "95/95 [==============================] - 17s 155ms/step - loss: 78.4469 - accuracy: 0.3484 - val_loss: 1.7744 - val_accuracy: 0.3550\n",
      "Epoch 2/2\n",
      "95/95 [==============================] - 13s 137ms/step - loss: 3.4931 - accuracy: 0.3149 - val_loss: 1.4043 - val_accuracy: 0.2700\n",
      "11/11 [==============================] - 1s 45ms/step\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2833  \u001b[0m | \u001b[0m 2.449   \u001b[0m | \u001b[0m 17.47   \u001b[0m | \u001b[0m 0.4361  \u001b[0m | \u001b[0m 0.2308  \u001b[0m | \u001b[0m 50.67   \u001b[0m | \u001b[0m 1.149   \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.00426 \u001b[0m | \u001b[0m 170.9   \u001b[0m | \u001b[0m 215.3   \u001b[0m | \u001b[0m 1.981   \u001b[0m |\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 15s 165ms/step - loss: 1.9292 - accuracy: 0.3035 - val_loss: 1.3027 - val_accuracy: 0.4450\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 1.3511 - accuracy: 0.3860 - val_loss: 1.1602 - val_accuracy: 0.4850\n",
      "10/10 [==============================] - 1s 32ms/step\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.4389  \u001b[0m | \u001b[95m 1.425   \u001b[0m | \u001b[95m 18.96   \u001b[0m | \u001b[95m 0.3746  \u001b[0m | \u001b[95m 0.1156  \u001b[0m | \u001b[95m 46.28   \u001b[0m | \u001b[95m 1.121   \u001b[0m | \u001b[95m 1.62    \u001b[0m | \u001b[95m 0.002611\u001b[0m | \u001b[95m 186.0   \u001b[0m | \u001b[95m 396.0   \u001b[0m | \u001b[95m 1.882   \u001b[0m |\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "77/77 [==============================] - 15s 176ms/step - loss: 1.2531 - accuracy: 0.4390 - val_loss: 1.1166 - val_accuracy: 0.4725\n",
      "Epoch 2/2\n",
      "77/77 [==============================] - 13s 171ms/step - loss: 0.8804 - accuracy: 0.6402 - val_loss: 0.8932 - val_accuracy: 0.6300\n",
      "9/9 [==============================] - 1s 59ms/step\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8     \u001b[0m | \u001b[95m 0.02029 \u001b[0m | \u001b[95m 20.91   \u001b[0m | \u001b[95m 0.111   \u001b[0m | \u001b[95m 0.2652  \u001b[0m | \u001b[95m 51.29   \u001b[0m | \u001b[95m 1.685   \u001b[0m | \u001b[95m 1.765   \u001b[0m | \u001b[95m 0.00405 \u001b[0m | \u001b[95m 188.9   \u001b[0m | \u001b[95m 390.7   \u001b[0m | \u001b[95m 0.1245  \u001b[0m |\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "35/35 [==============================] - 15s 393ms/step - loss: 1.9863 - accuracy: 0.3130 - val_loss: 1.2706 - val_accuracy: 0.4900\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 13s 376ms/step - loss: 1.3981 - accuracy: 0.3872 - val_loss: 1.4329 - val_accuracy: 0.3000\n",
      "4/4 [==============================] - 1s 170ms/step\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.3056  \u001b[0m | \u001b[0m 0.6047  \u001b[0m | \u001b[0m 46.77   \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 0.1415  \u001b[0m | \u001b[0m 72.17   \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m 1.217   \u001b[0m | \u001b[0m 0.006129\u001b[0m | \u001b[0m 313.5   \u001b[0m | \u001b[0m 120.7   \u001b[0m | \u001b[0m 1.589   \u001b[0m |\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 15s 513ms/step - loss: 1.7854 - accuracy: 0.3123 - val_loss: 1.3157 - val_accuracy: 0.4100\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 13s 510ms/step - loss: 1.2695 - accuracy: 0.4667 - val_loss: 1.1753 - val_accuracy: 0.5125\n",
      "3/3 [==============================] - 1s 260ms/step\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.4833  \u001b[0m | \u001b[0m 3.196   \u001b[0m | \u001b[0m 61.63   \u001b[0m | \u001b[0m 0.04053 \u001b[0m | \u001b[0m 0.2721  \u001b[0m | \u001b[0m 80.76   \u001b[0m | \u001b[0m 1.204   \u001b[0m | \u001b[0m 1.731   \u001b[0m | \u001b[0m 0.002568\u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 171.0   \u001b[0m | \u001b[0m 1.4     \u001b[0m |\n",
      "=============================================================================================================================================================\n",
      "It takes 2.728998064994812 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "# Set paramaters\n",
    "params_nn ={\n",
    "    'neurons1': (64, 512),\n",
    "    'neurons2': (64, 512),\n",
    "    'activation':(0, 4),\n",
    "    'optimizer':(0,2),\n",
    "    'learning_rate':(1e-4, 1e-2),\n",
    "    'batch_size':(8 ,64),\n",
    "    'epochs':(30,100),\n",
    "    'layers1':(1,2),\n",
    "    'layers2':(1,2),\n",
    "    'dropout': (0,1),\n",
    "    'dropout_rate': (0, 0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\n",
    "#n_iter: how many steps of Bayesian optimization you want to perform. \n",
    "#The more step the more likely to find a good maximum you are\n",
    "#init_points: How many teps of random exploration you want to perform. \n",
    "#Random exploration can help by diversifying the exploration space. \n",
    "nn_bo.maximize(init_points=10 , n_iter=4)\n",
    "print('It takes %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.8, 'params': {'activation': 0.020286305373350633, 'batch_size': 20.91169181452548, 'dropout': 0.1110226980489678, 'dropout_rate': 0.2652425035358042, 'epochs': 51.29466799425829, 'layers1': 1.6853542078693775, 'layers2': 1.7650189535072887, 'learning_rate': 0.00404963396222202, 'neurons1': 188.9195948518181, 'neurons2': 390.7419657419016, 'optimizer': 0.12452501756925849}}\n"
     ]
    }
   ],
   "source": [
    "print(nn_bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 21,\n",
       " 'dropout': 0.1110226980489678,\n",
       " 'dropout_rate': 0.2652425035358042,\n",
       " 'epochs': 51,\n",
       " 'layers1': 2,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.00404963396222202,\n",
       " 'neurons1': 189,\n",
       " 'neurons2': 391,\n",
       " 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x139351018b0>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_nn_ = nn_bo.max['params']\n",
    "learning_rate = params_nn_['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'selu', 'tanh', 'elu']\n",
    "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
    "params_nn_['batch_size'] = round(params_nn_['batch_size'])\n",
    "params_nn_['epochs'] = round(params_nn_['epochs'])\n",
    "params_nn_['layers1'] = round(params_nn_['layers1'])\n",
    "params_nn_['layers2'] = round(params_nn_['layers2'])\n",
    "params_nn_['neurons1'] = round(params_nn_['neurons1'])\n",
    "params_nn_['neurons2'] = round(params_nn_['neurons2'])\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop']\n",
    "optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate), 'RMSprop':RMSprop(lr=learning_rate)}           \n",
    "params_nn_['optimizer'] = optimizerD[optimizerL[round(params_nn_['optimizer'])]]\n",
    "params_nn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CNN_model():\n",
    "#     mobilenet = MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "#     for layer in mobilenet.layers:\n",
    "#         layer.trainable = False\n",
    "#     x = Flatten()(mobilenet.output)\n",
    "\n",
    "#     for i in range(layers1):\n",
    "#         x = Dense(neurons1, activation = activation)(x)\n",
    "#     if dropout > 0.5:\n",
    "#         x = Dropout(dropout_rate)(x)\n",
    "#     for i in range(layers2):\n",
    "#         x = Dense(neurons2, activation = activation)(x)\n",
    "\n",
    "#     prediction = Dense(len(classLabels), activation='softmax')(x)\n",
    "#     model = Model(inputs=mobilenet.input, outputs=prediction)\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])       \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "# skf.get_n_splits(X, Y)\n",
    "# foldNum = 0\n",
    "# for train_index, val_index in skf.split(X, Y):\n",
    "#     transferAllClassBetweenFolders('valid', 'train', 1.0)\n",
    "#     foldNum += 1\n",
    "#     X_train, X_val = X[train_index], X[val_index]\n",
    "#     Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "#     for eachIndex in range(len(X_val)):\n",
    "#         classLabel = ''\n",
    "#         for i in range(len(classLabels)):\n",
    "#             if(Y_val[eachIndex]==i):\n",
    "#                 classLabel=classLabels[i]\n",
    "#         shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
    "#                     datasetFolderName+'/valid/'+classLabel+'/'+X_val[eachIndex])   \n",
    "\n",
    "#     train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "#     validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#     test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#     train_generator = train_datagen.flow_from_directory(\n",
    "#         train_path,target_size=(img_rows, img_cols),\n",
    "#         batch_size=batch_size, class_mode='categorical', subset='training')     \n",
    "\n",
    "#     validation_generator = validation_datagen.flow_from_directory(\n",
    "#         validation_path,  target_size=(img_rows, img_cols),\n",
    "#         batch_size=batch_size, class_mode='categorical')   \n",
    "\n",
    "#     test_generator = test_datagen.flow_from_directory(\n",
    "#         test_path, target_size=(img_rows, img_cols),\n",
    "#         batch_size=batch_size,  class_mode=None, shuffle=False) \n",
    "\n",
    "\n",
    "# model1=CNN_model()\n",
    "# history=model1.fit_generator(train_generator, validation_data=validation_generator, epochs=epochs)\n",
    "\n",
    "# print(\"==============TEST RESULTS============\") \n",
    "# predictions = model1.predict(test_generator, verbose=1)\n",
    "# yPredictions = np.argmax(predictions, axis=1)\n",
    "# true_classes = test_generator.classes\n",
    "\n",
    "# testAcc, testPrec, testRecall, testFScore = my_metrics(true_classes, yPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2021/05/bayesian-optimization-bayes_opt-or-hyperopt/\n",
    "#https://machinelearningapplied.com/hyperparameter-search-with-bayesian-optimization-for-keras-cnn-classification-and-ensembling/\n",
    "#https://towardsdatascience.com/tune-deep-neural-networks-using-bayesian-optimization-c9f6503a049f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/tune-deep-neural-networks-using-bayesian-optimization-c9f6503a049f\n",
    "# https://www.kaggle.com/code/ishivinal/hyperparamters-optimization-gs-rs-boa-tpe-hb-ga"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
